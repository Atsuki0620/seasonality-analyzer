{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 季節性検出 探索的分析ノートブック\n",
    "\n",
    "## 目的\n",
    "製造業の不定期生産ロットデータから、複数の季節性検出手法を比較検証し、最適な分析パイプラインを設計する。\n",
    "\n",
    "## データ仕様\n",
    "- 入力：CSV（columns: date, time, sensor_1, sensor_2, ..., sensor_60）\n",
    "- 各センサー：1日あたり1〜50ロットの中央値を代表値として記録\n",
    "- 欠損率：1%未満\n",
    "- 期間：最大4年、長期休止（数週間〜数ヶ月）含む\n",
    "- 外れ値：スパイクノイズ、設備設定変更による突然の変化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 環境設定とライブラリインポート\n",
    "# ============================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import gc\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats, signal\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import ruptures as rpt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# 再現性のためのシード固定\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# 表示設定\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# 出力ディレクトリ\n",
    "OUTPUT_DIR = Path('results/exploration')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('ライブラリのインポート完了')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# セクション1：データ読み込みと基礎統計\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 CSVロード、timestamp生成、基本情報表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ??1: CSV????timestamp??\n",
    "# ============================================================\n",
    "\n",
    "# ?????????????????????????\n",
    "DATA_PATH = Path('../data/sample_sensor_data.csv')\n",
    "# ??????????????????????????????????\n",
    "if not DATA_PATH.exists():\n",
    "    alt = Path.cwd().parent / 'data' / 'sample_sensor_data.csv'\n",
    "    if alt.exists():\n",
    "        DATA_PATH = alt\n",
    "    else:\n",
    "        raise FileNotFoundError(f'???????????????: {DATA_PATH} / {alt}')\n",
    "print(f'DATA_PATH: {DATA_PATH}')\n",
    "\n",
    "# CSV???\n",
    "df_raw = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# timestamp???date + time?????\n",
    "if 'time' in df_raw.columns:\n",
    "    df_raw['timestamp'] = pd.to_datetime(df_raw['date'] + ' ' + df_raw['time'])\n",
    "else:\n",
    "    df_raw['timestamp'] = pd.to_datetime(df_raw['date'])\n",
    "\n",
    "# timestamp??????????\n",
    "df_raw = df_raw.set_index('timestamp').sort_index()\n",
    "\n",
    "# ???????\n",
    "cols_to_drop = [col for col in ['date', 'time'] if col in df_raw.columns]\n",
    "df_raw = df_raw.drop(columns=cols_to_drop)\n",
    "\n",
    "# ????????\n",
    "sensor_cols = [col for col in df_raw.columns if col.startswith('sensor_')]\n",
    "\n",
    "print('=== ??????? ===')\n",
    "print(f'?????: {df_raw.index.min()} ? {df_raw.index.max()}')\n",
    "print(f'??????: {len(df_raw):,}')\n",
    "print(f'?????: {len(sensor_cols)}')\n",
    "print(f'?????: {sensor_cols[:5]}...' if len(sensor_cols) > 5 else f'?????: {sensor_cols}')\n",
    "print(f'\\n????:\\n{df_raw.dtypes}')\n",
    "print(f'\\n??5?:\\n{df_raw.head()}')\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 欠損パターンの可視化（ヒートマップ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# セル2: 欠損パターンの可視化\n",
    "# ============================================================\n",
    "\n",
    "# 欠損値の概要\n",
    "missing_summary = df_raw[sensor_cols].isnull().sum()\n",
    "missing_pct = (missing_summary / len(df_raw) * 100).round(2)\n",
    "\n",
    "print('=== 欠損値サマリー ===')\n",
    "print(f'欠損があるセンサー数: {(missing_summary > 0).sum()}')\n",
    "print(f'最大欠損率: {missing_pct.max():.2f}%')\n",
    "\n",
    "# 月別欠損パターンのヒートマップ\n",
    "df_monthly_missing = df_raw[sensor_cols].resample('ME').apply(lambda x: x.isnull().sum())\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# 左: センサー別欠損率\n",
    "ax1 = axes[0]\n",
    "missing_pct.plot(kind='bar', ax=ax1, color='coral')\n",
    "ax1.set_title('センサー別欠損率')\n",
    "ax1.set_xlabel('センサー')\n",
    "ax1.set_ylabel('欠損率 (%)')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 右: 月別×センサー別欠損ヒートマップ\n",
    "ax2 = axes[1]\n",
    "if len(df_monthly_missing) > 0 and df_monthly_missing.values.sum() > 0:\n",
    "    sns.heatmap(df_monthly_missing.T, cmap='YlOrRd', ax=ax2, cbar_kws={'label': '欠損数'})\n",
    "    ax2.set_title('月別×センサー別 欠損パターン')\n",
    "    ax2.set_xlabel('月')\n",
    "    ax2.set_ylabel('センサー')\n",
    "else:\n",
    "    ax2.text(0.5, 0.5, '欠損なし', ha='center', va='center', fontsize=14)\n",
    "    ax2.set_title('月別×センサー別 欠損パターン')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'missing_pattern.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 各センサーの記述統計（平均、標準偏差、歪度、尖度）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# セル3: 記述統計\n",
    "# ============================================================\n",
    "\n",
    "def calc_descriptive_stats(series):\n",
    "    \"\"\"センサー単位の記述統計を計算\"\"\"\n",
    "    return pd.Series({\n",
    "        'count': series.count(),\n",
    "        'mean': series.mean(),\n",
    "        'std': series.std(),\n",
    "        'min': series.min(),\n",
    "        'q25': series.quantile(0.25),\n",
    "        'median': series.median(),\n",
    "        'q75': series.quantile(0.75),\n",
    "        'max': series.max(),\n",
    "        'skewness': stats.skew(series.dropna()),\n",
    "        'kurtosis': stats.kurtosis(series.dropna()),\n",
    "        'cv': series.std() / series.mean() if series.mean() != 0 else np.nan  # 変動係数\n",
    "    })\n",
    "\n",
    "# 全センサーの記述統計を計算\n",
    "desc_stats = df_raw[sensor_cols].apply(calc_descriptive_stats).T\n",
    "desc_stats = desc_stats.round(4)\n",
    "\n",
    "print('=== 記述統計 ===')\n",
    "display(desc_stats)\n",
    "\n",
    "# CSV出力\n",
    "desc_stats.to_csv(OUTPUT_DIR / 'descriptive_statistics.csv')\n",
    "print(f'\\n保存: {OUTPUT_DIR / \"descriptive_statistics.csv\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 時系列プロット（全センサー、サブプロット形式）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# セル4: 時系列プロット\n",
    "# ============================================================\n",
    "\n",
    "n_sensors = len(sensor_cols)\n",
    "n_cols = 2\n",
    "n_rows = (n_sensors + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 3 * n_rows), sharex=True)\n",
    "axes = axes.flatten() if n_sensors > 1 else [axes]\n",
    "\n",
    "for i, col in enumerate(sensor_cols):\n",
    "    ax = axes[i]\n",
    "    ax.plot(df_raw.index, df_raw[col], linewidth=0.5, alpha=0.8)\n",
    "    ax.set_title(col)\n",
    "    ax.set_ylabel('値')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 余ったサブプロットを非表示\n",
    "for i in range(n_sensors, len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.xlabel('日付')\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'time_series_all_sensors.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# セクション2：前処理の比較検証\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 不等間隔データの扱い\n",
    "\n",
    "### 理論背景\n",
    "製造データは生産スケジュールに依存するため、不等間隔になりやすい。\n",
    "季節性検出の多くの手法（FFT、STLなど）は等間隔データを前提とするため、\n",
    "リサンプリングと補間が必要になる。\n",
    "\n",
    "- **リサンプリング手法**: mean（平均）、median（中央値）、ffill（前方埋め）\n",
    "- **補間手法**: linear（線形）、spline（スプライン）、None（補間なし=NaN維持）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# セル5: リサンプリング・補間手法の比較\n",
    "# ============================================================\n",
    "\n",
    "def resample_and_interpolate(df, sensor_col, resample_method='mean', interp_method='linear'):\n",
    "    \"\"\"\n",
    "    日次リサンプリングと補間を実行\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        入力データ（timestampがインデックス）\n",
    "    sensor_col : str\n",
    "        対象センサー列名\n",
    "    resample_method : str\n",
    "        'mean', 'median', 'ffill'\n",
    "    interp_method : str or None\n",
    "        'linear', 'spline', None\n",
    "    \"\"\"\n",
    "    series = df[sensor_col].copy()\n",
    "    \n",
    "    # 日次リサンプリング\n",
    "    if resample_method == 'mean':\n",
    "        resampled = series.resample('D').mean()\n",
    "    elif resample_method == 'median':\n",
    "        resampled = series.resample('D').median()\n",
    "    elif resample_method == 'ffill':\n",
    "        resampled = series.resample('D').ffill()\n",
    "    else:\n",
    "        raise ValueError(f'Unknown resample_method: {resample_method}')\n",
    "    \n",
    "    # 補間\n",
    "    if interp_method == 'linear':\n",
    "        resampled = resampled.interpolate(method='linear')\n",
    "    elif interp_method == 'spline':\n",
    "        resampled = resampled.interpolate(method='spline', order=3)\n",
    "    elif interp_method is None:\n",
    "        pass  # NaN維持\n",
    "    else:\n",
    "        raise ValueError(f'Unknown interp_method: {interp_method}')\n",
    "    \n",
    "    return resampled\n",
    "\n",
    "# 代表センサー3本を選択（先頭3つ）\n",
    "representative_sensors = sensor_cols[:3]\n",
    "\n",
    "# 各組み合わせで処理\n",
    "resample_methods = ['mean', 'median', 'ffill']\n",
    "interp_methods = ['linear', 'spline', None]\n",
    "\n",
    "# 結果格納\n",
    "resampled_results = {}\n",
    "\n",
    "for sensor in representative_sensors:\n",
    "    resampled_results[sensor] = {}\n",
    "    for rm in resample_methods:\n",
    "        for im in interp_methods:\n",
    "            key = f'{rm}_{im}'\n",
    "            resampled_results[sensor][key] = resample_and_interpolate(\n",
    "                df_raw, sensor, resample_method=rm, interp_method=im\n",
    "            )\n",
    "\n",
    "print(f'処理完了: {len(representative_sensors)}センサー × {len(resample_methods)}リサンプリング × {len(interp_methods)}補間 = {len(representative_sensors) * len(resample_methods) * len(interp_methods)}パターン')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# セル5b: リサンプリング・補間結果の可視化\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(len(representative_sensors), 3, figsize=(18, 4 * len(representative_sensors)))\n",
    "\n",
    "for i, sensor in enumerate(representative_sensors):\n",
    "    for j, rm in enumerate(resample_methods):\n",
    "        ax = axes[i, j] if len(representative_sensors) > 1 else axes[j]\n",
    "        \n",
    "        for im in interp_methods:\n",
    "            key = f'{rm}_{im}'\n",
    "            label = f'interp={im}' if im else 'interp=None'\n",
    "            data = resampled_results[sensor][key]\n",
    "            ax.plot(data.index, data.values, label=label, alpha=0.7, linewidth=0.8)\n",
    "        \n",
    "        ax.set_title(f'{sensor} - resample={rm}')\n",
    "        ax.legend(loc='upper right', fontsize=8)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'resampling_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 外れ値検出\n",
    "\n",
    "### 理論背景\n",
    "- **IQR法**: 四分位範囲（Q3-Q1）の1.5倍を超える値を外れ値とする古典的手法\n",
    "- **Z-score**: 平均から標準偏差の何倍離れているかで判定（通常|z|>3）\n",
    "- **Isolation Forest**: 異常値は「孤立しやすい」という性質を利用した機械学習手法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# セル6: 外れ値検出手法の比較\n",
    "# ============================================================\n",
    "\n",
    "def detect_outliers_iqr(series, k=1.5):\n",
    "    \"\"\"IQR法による外れ値検出\"\"\"\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - k * IQR\n",
    "    upper = Q3 + k * IQR\n",
    "    return (series < lower) | (series > upper)\n",
    "\n",
    "def detect_outliers_zscore(series, threshold=3):\n",
    "    \"\"\"Z-score法による外れ値検出\"\"\"\n",
    "    z = np.abs(stats.zscore(series.dropna()))\n",
    "    outlier_idx = series.dropna().index[z > threshold]\n",
    "    return series.index.isin(outlier_idx)\n",
    "\n",
    "def detect_outliers_isolation_forest(series, contamination=0.05, random_state=RANDOM_SEED):\n",
    "    \"\"\"Isolation Forestによる外れ値検出\"\"\"\n",
    "    data = series.dropna().values.reshape(-1, 1)\n",
    "    iso = IsolationForest(contamination=contamination, random_state=random_state)\n",
    "    preds = iso.fit_predict(data)\n",
    "    outlier_idx = series.dropna().index[preds == -1]\n",
    "    return series.index.isin(outlier_idx)\n",
    "\n",
    "# 代表センサーで各手法を適用（日次リサンプリング後のデータを使用）\n",
    "outlier_results = {}\n",
    "\n",
    "for sensor in tqdm(representative_sensors, desc='外れ値検出'):\n",
    "    # mean + linear補間のデータを使用\n",
    "    data = resampled_results[sensor]['mean_linear'].dropna()\n",
    "    \n",
    "    outlier_results[sensor] = {\n",
    "        'data': data,\n",
    "        'iqr': detect_outliers_iqr(data),\n",
    "        'zscore': detect_outliers_zscore(data),\n",
    "        'iforest': detect_outliers_isolation_forest(data)\n",
    "    }\n",
    "\n",
    "# 外れ値検出数の比較\n",
    "outlier_summary = pd.DataFrame({\n",
    "    sensor: {\n",
    "        'IQR': outlier_results[sensor]['iqr'].sum(),\n",
    "        'Z-score': outlier_results[sensor]['zscore'].sum(),\n",
    "        'IsolationForest': outlier_results[sensor]['iforest'].sum(),\n",
    "        'Total Points': len(outlier_results[sensor]['data'])\n",
    "    }\n",
    "    for sensor in representative_sensors\n",
    "}).T\n",
    "\n",
    "print('=== 外れ値検出数の比較 ===')\n",
    "display(outlier_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# セル6b: 外れ値の時系列プロット\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(len(representative_sensors), 1, figsize=(16, 4 * len(representative_sensors)))\n",
    "axes = [axes] if len(representative_sensors) == 1 else axes\n",
    "\n",
    "for i, sensor in enumerate(representative_sensors):\n",
    "    ax = axes[i]\n",
    "    data = outlier_results[sensor]['data']\n",
    "    \n",
    "    # ベースの時系列\n",
    "    ax.plot(data.index, data.values, 'b-', linewidth=0.5, alpha=0.6, label='Data')\n",
    "    \n",
    "    # 各手法の外れ値をマーカーで表示\n",
    "    methods = [('iqr', 'IQR', 'ro', 8), ('zscore', 'Z-score', 'g^', 8), ('iforest', 'IForest', 'ms', 6)]\n",
    "    \n",
    "    for method_key, method_name, marker, size in methods:\n",
    "        mask = outlier_results[sensor][method_key]\n",
    "        outlier_data = data[mask]\n",
    "        ax.scatter(outlier_data.index, outlier_data.values, \n",
    "                   marker=marker[1], c=marker[0], s=size**2, label=method_name, alpha=0.7)\n",
    "    \n",
    "    ax.set_title(f'{sensor} - 外れ値検出結果')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'outlier_detection_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Changepoint Detection（構造変化点検出）\n",
    "\n",
    "### 理論背景\n",
    "製造プロセスでは設備変更や工程変更により、時系列の統計的性質が突然変化することがある。\n",
    "この変化点を検出し、セグメントごとに季節性を分析することで精度向上が期待できる。\n",
    "\n",
    "- **PELT法**: Pruned Exact Linear Time - 最適なコスト関数を持つ変化点を高速検出\n",
    "- **Window法**: スライディングウィンドウで局所的な変化を検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# セル7: Changepoint Detection\n",
    "# ============================================================\n",
    "\n",
    "def detect_changepoints(series, method='pelt', model='rbf', min_size=30, penalty=10):\n",
    "    \"\"\"\n",
    "    rupturesによる変化点検出\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    series : pd.Series\n",
    "        入力時系列\n",
    "    method : str\n",
    "        'pelt' or 'window'\n",
    "    model : str\n",
    "        コストモデル（'rbf', 'l1', 'l2'）\n",
    "    min_size : int\n",
    "        最小セグメント長\n",
    "    penalty : float\n",
    "        ペナルティパラメータ（変化点数を制御）\n",
    "    \"\"\"\n",
    "    data = series.dropna().values\n",
    "    \n",
    "    if method == 'pelt':\n",
    "        algo = rpt.Pelt(model=model, min_size=min_size).fit(data)\n",
    "        result = algo.predict(pen=penalty)\n",
    "    elif method == 'window':\n",
    "        algo = rpt.Window(model=model, min_size=min_size, width=50).fit(data)\n",
    "        result = algo.predict(pen=penalty)\n",
    "    else:\n",
    "        raise ValueError(f'Unknown method: {method}')\n",
    "    \n",
    "    # インデックスに変換\n",
    "    change_indices = [series.dropna().index[i-1] for i in result[:-1]]\n",
    "    return change_indices\n",
    "\n",
    "# 変化点検出の実行\n",
    "changepoint_results = {}\n",
    "\n",
    "for sensor in tqdm(representative_sensors, desc='変化点検出'):\n",
    "    data = resampled_results[sensor]['mean_linear'].dropna()\n",
    "    \n",
    "    changepoint_results[sensor] = {\n",
    "        'data': data,\n",
    "        'pelt': detect_changepoints(data, method='pelt', penalty=10),\n",
    "        'window': detect_changepoints(data, method='window', penalty=10)\n",
    "    }\n",
    "\n",
    "# 検出された変化点数\n",
    "print('=== 検出された変化点数 ===')\n",
    "for sensor in representative_sensors:\n",
    "    print(f'{sensor}: PELT={len(changepoint_results[sensor][\"pelt\"])}, Window={len(changepoint_results[sensor][\"window\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# セル7b: 変化点の可視化\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(len(representative_sensors), 1, figsize=(16, 4 * len(representative_sensors)))\n",
    "axes = [axes] if len(representative_sensors) == 1 else axes\n",
    "\n",
    "for i, sensor in enumerate(representative_sensors):\n",
    "    ax = axes[i]\n",
    "    data = changepoint_results[sensor]['data']\n",
    "    \n",
    "    # 時系列プロット\n",
    "    ax.plot(data.index, data.values, 'b-', linewidth=0.5, alpha=0.8, label='Data')\n",
    "    \n",
    "    # PELT変化点（赤縦線）\n",
    "    for cp in changepoint_results[sensor]['pelt']:\n",
    "        ax.axvline(x=cp, color='red', linestyle='--', linewidth=1.5, alpha=0.7, label='PELT' if cp == changepoint_results[sensor]['pelt'][0] else '')\n",
    "    \n",
    "    # Window変化点（緑縦線）\n",
    "    for cp in changepoint_results[sensor]['window']:\n",
    "        ax.axvline(x=cp, color='green', linestyle=':', linewidth=1.5, alpha=0.7, label='Window' if cp == changepoint_results[sensor]['window'][0] else '')\n",
    "    \n",
    "    ax.set_title(f'{sensor} - 変化点検出結果')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'changepoint_detection.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# セル7c: 変化点前後のセグメント統計比較\n",
    "# ============================================================\n",
    "\n",
    "def segment_statistics(series, changepoints):\n",
    "    \"\"\"変化点で分割したセグメントの統計を計算\"\"\"\n",
    "    segments = []\n",
    "    boundaries = [series.index[0]] + list(changepoints) + [series.index[-1]]\n",
    "    \n",
    "    for j in range(len(boundaries) - 1):\n",
    "        start, end = boundaries[j], boundaries[j+1]\n",
    "        segment = series[start:end]\n",
    "        segments.append({\n",
    "            'segment': j + 1,\n",
    "            'start': start,\n",
    "            'end': end,\n",
    "            'n_points': len(segment),\n",
    "            'mean': segment.mean(),\n",
    "            'std': segment.std(),\n",
    "            'min': segment.min(),\n",
    "            'max': segment.max()\n",
    "        })\n",
    "    return pd.DataFrame(segments)\n",
    "\n",
    "# 代表センサーのセグメント統計（PELT変化点を使用）\n",
    "print('=== セグメント統計（PELT変化点） ===')\n",
    "for sensor in representative_sensors:\n",
    "    data = changepoint_results[sensor]['data']\n",
    "    cps = changepoint_results[sensor]['pelt']\n",
    "    seg_stats = segment_statistics(data, cps)\n",
    "    print(f'\\n{sensor}:')\n",
    "    display(seg_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# セクション3：季節性検出手法の実装と比較\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 STL分解（Seasonal-Trend decomposition using Loess）\n",
    "\n",
    "### 理論背景\n",
    "STLは時系列を**Trend（トレンド）**、**Seasonal（季節成分）**、**Residual（残差）**の3成分に分解する手法。\n",
    "局所重み付け回帰（LOESS）を使用し、外れ値にロバスト。\n",
    "\n",
    "**季節成分の強度スコア**: $F_{season} = \\frac{Var(Seasonal)}{Var(Residual)}$\n",
    "\n",
    "F_seasonが大きいほど季節性が強い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# セル8: STL分解\n",
    "# ============================================================\n",
    "\n",
    "def perform_stl_decomposition(series, period):\n",
    "    \"\"\"\n",
    "    STL分解を実行し、季節性強度スコアを計算\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    series : pd.Series\n",
    "        入力時系列（等間隔・欠損なし）\n",
    "    period : int\n",
    "        季節周期（日数）\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict: 分解結果とスコア\n",
    "    \"\"\"\n",
    "    # データ長チェック\n",
    "    if len(series) < 2 * period:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        stl = STL(series, period=period, robust=True)\n",
    "        result = stl.fit()\n",
    "        \n",
    "        # 季節性強度スコア\n",
    "        var_seasonal = np.var(result.seasonal)\n",
    "        var_residual = np.var(result.resid)\n",
    "        f_season = var_seasonal / var_residual if var_residual > 0 else 0\n",
    "        \n",
    "        # 正規化スコア（0-1にクリップ）\n",
    "        score_normalized = min(f_season / (f_season + 1), 1.0)\n",
    "        \n",
    "        return {\n",
    "            'trend': result.trend,\n",
    "            'seasonal': result.seasonal,\n",
    "            'residual': result.resid,\n",
    "            'f_season': f_season,\n",
    "            'score': score_normalized\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f'STL error (period={period}): {e}')\n",
    "        return None\n",
    "\n",
    "# 周期候補\n",
    "periods = [7, 30, 365]\n",
    "\n",
    "# STL分解結果の格納\n",
    "stl_results = {}\n",
    "\n",
    "for sensor in tqdm(representative_sensors, desc='STL分解'):\n",
    "    data = resampled_results[sensor]['mean_linear'].dropna()\n",
    "    stl_results[sensor] = {}\n",
    "    \n",
    "    for period in periods:\n",
    "        result = perform_stl_decomposition(data, period)\n",
    "        if result:\n",
    "            stl_results[sensor][period] = result\n",
    "\n",
    "# スコアサマリー\n",
    "stl_scores = pd.DataFrame({\n",
    "    sensor: {\n",
    "        f'period_{p}': stl_results[sensor].get(p, {}).get('score', np.nan)\n",
    "        for p in periods\n",
    "    }\n",
    "    for sensor in representative_sensors\n",
    "}).T\n",
    "\n",
    "print('=== STL季節性スコア（F_season正規化） ===')\n",
    "display(stl_scores.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# セル8b: STL分解結果の可視化\n",
    "# ============================================================\n",
    "\n",
    "# 最初のセンサーについて、各周期でのSTL分解を表示\n",
    "sensor = representative_sensors[0]\n",
    "\n",
    "fig, axes = plt.subplots(len(periods), 4, figsize=(18, 4 * len(periods)))\n",
    "\n",
    "for i, period in enumerate(periods):\n",
    "    if period not in stl_results[sensor]:\n",
    "        continue\n",
    "    \n",
    "    result = stl_results[sensor][period]\n",
    "    data = resampled_results[sensor]['mean_linear'].dropna()\n",
    "    \n",
    "    # Original\n",
    "    axes[i, 0].plot(data.index, data.values, 'b-', linewidth=0.5)\n",
    "    axes[i, 0].set_title(f'Original (period={period}d)')\n",
    "    axes[i, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Trend\n",
    "    axes[i, 1].plot(data.index, result['trend'], 'g-', linewidth=1)\n",
    "    axes[i, 1].set_title('Trend')\n",
    "    axes[i, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Seasonal\n",
    "    axes[i, 2].plot(data.index, result['seasonal'], 'r-', linewidth=0.5)\n",
    "    axes[i, 2].set_title(f'Seasonal (score={result[\"score\"]:.3f})')\n",
    "    axes[i, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Residual\n",
    "    axes[i, 3].plot(data.index, result['residual'], 'gray', linewidth=0.5)\n",
    "    axes[i, 3].set_title('Residual')\n",
    "    axes[i, 3].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(f'{sensor} - STL Decomposition', y=1.02, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / f'stl_decomposition_{sensor}.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 自己相関関数（ACF/PACF）\n",
    "\n",
    "### 理論背景\n",
    "ACF（自己相関関数）は、時系列とそのラグ版との相関を測定。\n",
    "季節性がある場合、その周期に対応するラグで相関のピークが現れる。\n",
    "\n",
    "**検出基準**: 95%信頼区間（$\\pm 1.96/\\sqrt{n}$）を超えるピーク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# セル9: ACF/PACF計算\n",
    "# ============================================================\n",
    "\n",
    "def calculate_acf_peaks(series, max_lag=400, target_periods=[7, 30, 365], tolerance=3):\n",
    "    \"\"\"\n",
    "    ACFを計算し、特定周期付近のピークを検出\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    series : pd.Series\n",
    "        入力時系列\n",
    "    max_lag : int\n",
    "        最大ラグ\n",
    "    target_periods : list\n",
    "        検出したい周期のリスト\n",
    "    tolerance : int\n",
    "        ピーク検出の許容範囲（日数）\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict: ACF値、信頼区間、ピーク情報\n",
    "    \"\"\"\n",
    "    data = series.dropna().values\n",
    "    n = len(data)\n",
    "    \n",
    "    # max_lagの調整\n",
    "    max_lag = min(max_lag, n // 2 - 1)\n",
    "    \n",
    "    if max_lag < 10:\n",
    "        return None\n",
    "    \n",
    "    # ACF計算\n",
    "    acf_values = acf(data, nlags=max_lag, fft=True)\n",
    "    \n",
    "    # 95%信頼区間\n",
    "    conf_int = 1.96 / np.sqrt(n)\n",
    "    \n",
    "    # 各周期付近のピーク値を抽出\n",
    "    peak_info = {}\n",
    "    for period in target_periods:\n",
    "        if period > max_lag:\n",
    "            peak_info[period] = {'value': np.nan, 'significant': False, 'actual_lag': np.nan}\n",
    "            continue\n",
    "        \n",
    "        # 周期付近の範囲\n",
    "        start = max(1, period - tolerance)\n",
    "        end = min(max_lag, period + tolerance)\n",
    "        \n",
    "        # 範囲内の最大ACF値\n",
    "        acf_range = acf_values[start:end+1]\n",
    "        max_idx = np.argmax(np.abs(acf_range))\n",
    "        peak_value = acf_range[max_idx]\n",
    "        actual_lag = start + max_idx\n",
    "        \n",
    "        peak_info[period] = {\n",
    "            'value': peak_value,\n",
    "            'significant': abs(peak_value) > conf_int,\n",
    "            'actual_lag': actual_lag\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        'acf': acf_values,\n",
    "        'conf_int': conf_int,\n",
    "        'peaks': peak_info\n",
    "    }\n",
    "\n",
    "# ACF計算\n",
    "acf_results = {}\n",
    "\n",
    "for sensor in tqdm(representative_sensors, desc='ACF計算'):\n",
    "    data = resampled_results[sensor]['mean_linear'].dropna()\n",
    "    acf_results[sensor] = calculate_acf_peaks(data)\n",
    "\n",
    "# ピークサマリー\n",
    "print('=== ACFピーク値（95%信頼区間外は*）===')\n",
    "for sensor in representative_sensors:\n",
    "    if acf_results[sensor] is None:\n",
    "        continue\n",
    "    print(f'\\n{sensor}:')\n",
    "    for period, info in acf_results[sensor]['peaks'].items():\n",
    "        sig = '*' if info['significant'] else ''\n",
    "        print(f'  周期{period}d: ACF={info[\"value\"]:.4f}{sig} (lag={info[\"actual_lag\"]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# セル9b: ACF/PACFプロット\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(len(representative_sensors), 2, figsize=(16, 4 * len(representative_sensors)))\n",
    "if len(representative_sensors) == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for i, sensor in enumerate(representative_sensors):\n",
    "    data = resampled_results[sensor]['mean_linear'].dropna()\n",
    "    max_lag = min(400, len(data) // 2 - 1)\n",
    "    \n",
    "    if max_lag < 10:\n",
    "        continue\n",
    "    \n",
    "    # ACF\n",
    "    plot_acf(data, ax=axes[i, 0], lags=max_lag, alpha=0.05)\n",
    "    axes[i, 0].set_title(f'{sensor} - ACF')\n",
    "    \n",
    "    # 周期位置をマーク\n",
    "    for period in [7, 30, 365]:\n",
    "        if period <= max_lag:\n",
    "            axes[i, 0].axvline(x=period, color='red', linestyle='--', alpha=0.5, label=f'{period}d')\n",
    "    axes[i, 0].legend(loc='upper right')\n",
    "    \n",
    "    # PACF\n",
    "    plot_pacf(data, ax=axes[i, 1], lags=min(50, max_lag), alpha=0.05, method='ywm')\n",
    "    axes[i, 1].set_title(f'{sensor} - PACF')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'acf_pacf_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Periodogram（スペクトル解析）- Lomb-Scargle\n",
    "\n",
    "### 理論背景\n",
    "Lomb-Scargle periodogramは**不等間隔データに対応**したスペクトル解析手法。\n",
    "周波数領域で周期性を検出し、FFTの一般化と見なせる。\n",
    "\n",
    "**検出基準**: 偽陽性確率（FAP: False Alarm Probability）が有意水準（通常5%）未満のピーク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# セル10: Lomb-Scargle Periodogram\n",
    "# ============================================================\n",
    "from scipy.signal import lombscargle\n",
    "from astropy.timeseries import LombScargle  # より高機能な実装\n",
    "\n",
    "def calculate_lomb_scargle(series, target_periods=[7, 30, 365]):\n",
    "    \"\"\"\n",
    "    Lomb-Scargle periodogramを計算\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    series : pd.Series\n",
    "        入力時系列（timestampインデックス）\n",
    "    target_periods : list\n",
    "        検出したい周期（日数）\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict: 周波数、パワー、ピーク情報\n",
    "    \"\"\"\n",
    "    data = series.dropna()\n",
    "    \n",
    "    # 時間を日数に変換（最初の日からの経過日数）\n",
    "    t = (data.index - data.index[0]).days.values.astype(float)\n",
    "    y = data.values\n",
    "    \n",
    "    # 平均除去\n",
    "    y = y - np.mean(y)\n",
    "    \n",
    "    # 周波数グリッド（周期2日〜500日に対応）\n",
    "    min_freq = 1 / 500  # 最小周波数（最大周期500日）\n",
    "    max_freq = 1 / 2    # 最大周波数（最小周期2日）\n",
    "    \n",
    "    # LombScargleオブジェクト\n",
    "    ls = LombScargle(t, y)\n",
    "    \n",
    "    # 周波数グリッドを生成\n",
    "    frequency, power = ls.autopower(minimum_frequency=min_freq, maximum_frequency=max_freq)\n",
    "    \n",
    "    # 周期に変換\n",
    "    periods = 1 / frequency\n",
    "    \n",
    "    # ターゲット周期付近のピーク検出\n",
    "    peak_info = {}\n",
    "    for target_p in target_periods:\n",
    "        # ターゲット周期の±20%範囲\n",
    "        mask = (periods > target_p * 0.8) & (periods < target_p * 1.2)\n",
    "        if mask.sum() > 0:\n",
    "            idx = np.argmax(power[mask])\n",
    "            peak_power = power[mask][idx]\n",
    "            peak_period = periods[mask][idx]\n",
    "            \n",
    "            # FAP（偽陽性確率）の計算\n",
    "            fap = ls.false_alarm_probability(peak_power)\n",
    "            \n",
    "            peak_info[target_p] = {\n",
    "                'power': peak_power,\n",
    "                'actual_period': peak_period,\n",
    "                'fap': fap,\n",
    "                'significant': fap < 0.05\n",
    "            }\n",
    "        else:\n",
    "            peak_info[target_p] = {'power': np.nan, 'actual_period': np.nan, 'fap': np.nan, 'significant': False}\n",
    "    \n",
    "    return {\n",
    "        'frequency': frequency,\n",
    "        'power': power,\n",
    "        'periods': periods,\n",
    "        'peaks': peak_info\n",
    "    }\n",
    "\n",
    "# Lomb-Scargle計算（astropy必要）\n",
    "try:\n",
    "    ls_results = {}\n",
    "    for sensor in tqdm(representative_sensors, desc='Lomb-Scargle'):\n",
    "        data = resampled_results[sensor]['mean_linear']\n",
    "        ls_results[sensor] = calculate_lomb_scargle(data)\n",
    "    \n",
    "    # ピークサマリー\n",
    "    print('=== Lomb-Scargleピーク（FAP<0.05は*）===')\n",
    "    for sensor in representative_sensors:\n",
    "        print(f'\\n{sensor}:')\n",
    "        for period, info in ls_results[sensor]['peaks'].items():\n",
    "            sig = '*' if info['significant'] else ''\n",
    "            print(f'  周期{period}d: Power={info[\"power\"]:.4f}, 実周期={info[\"actual_period\"]:.1f}d, FAP={info[\"fap\"]:.4f}{sig}')\n",
    "            \n",
    "except ImportError:\n",
    "    print('astropy未インストール。pip install astropy でインストールしてください。')\n",
    "    ls_results = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# セル10b: Periodogramの可視化\n",
    "# ============================================================\n",
    "\n",
    "if ls_results:\n",
    "    fig, axes = plt.subplots(len(representative_sensors), 1, figsize=(14, 4 * len(representative_sensors)))\n",
    "    axes = [axes] if len(representative_sensors) == 1 else axes\n",
    "    \n",
    "    for i, sensor in enumerate(representative_sensors):\n",
    "        ax = axes[i]\n",
    "        result = ls_results[sensor]\n",
    "        \n",
    "        # パワースペクトル（周期でプロット）\n",
    "        ax.plot(result['periods'], result['power'], 'b-', linewidth=0.5)\n",
    "        ax.set_xlim(0, 400)\n",
    "        ax.set_xlabel('周期（日）')\n",
    "        ax.set_ylabel('Power')\n",
    "        ax.set_title(f'{sensor} - Lomb-Scargle Periodogram')\n",
    "        \n",
    "        # ターゲット周期にマーカー\n",
    "        for period in [7, 30, 365]:\n",
    "            ax.axvline(x=period, color='red', linestyle='--', alpha=0.5)\n",
    "            ax.annotate(f'{period}d', (period, ax.get_ylim()[1]*0.9), fontsize=9, color='red')\n",
    "        \n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / 'lomb_scargle_periodogram.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Fourier回帰による周期フィッティング\n",
    "\n",
    "### 理論背景\n",
    "周期Tのsin/cos項を説明変数に加えた線形回帰モデル：\n",
    "\n",
    "$y_t = \\beta_0 + \\beta_1 \\sin(2\\pi t/T) + \\beta_2 \\cos(2\\pi t/T) + \\epsilon_t$\n",
    "\n",
    "**季節性スコア**: $\\Delta R^2 = R^2_{with\\_season} - R^2_{baseline}$\n",
    "\n",
    "周期項を追加した際のR²の改善量が大きいほど、その周期の季節性が強い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# セル11: Fourier回帰\n",
    "# ============================================================\n",
    "\n",
    "def fourier_regression(series, periods=[7, 30, 365]):\n",
    "    \"\"\"\n",
    "    Fourier回帰による周期フィッティング\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    series : pd.Series\n",
    "        入力時系列\n",
    "    periods : list\n",
    "        フィッティングする周期（日数）\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict: 各周期のR²スコアとΔR²\n",
    "    \"\"\"\n",
    "    data = series.dropna()\n",
    "    \n",
    "    # 時間変数（日数）\n",
    "    t = (data.index - data.index[0]).days.values.astype(float)\n",
    "    y = data.values\n",
    "    \n",
    "    # ベースラインモデル（定数のみ）\n",
    "    X_base = np.ones((len(t), 1))\n",
    "    model_base = LinearRegression().fit(X_base, y)\n",
    "    r2_base = r2_score(y, model_base.predict(X_base))\n",
    "    \n",
    "    results = {'baseline_r2': r2_base}\n",
    "    \n",
    "    for period in periods:\n",
    "        # Fourier特徴量\n",
    "        sin_term = np.sin(2 * np.pi * t / period)\n",
    "        cos_term = np.cos(2 * np.pi * t / period)\n",
    "        \n",
    "        # 単一周期モデル\n",
    "        X_single = np.column_stack([np.ones(len(t)), sin_term, cos_term])\n",
    "        model_single = LinearRegression().fit(X_single, y)\n",
    "        r2_single = r2_score(y, model_single.predict(X_single))\n",
    "        \n",
    "        delta_r2 = r2_single - r2_base\n",
    "        \n",
    "        results[period] = {\n",
    "            'r2': r2_single,\n",
    "            'delta_r2': delta_r2,\n",
    "            'prediction': model_single.predict(X_single)\n",
    "        }\n",
    "    \n",
    "    # 全周期を含むモデル\n",
    "    X_full = [np.ones(len(t))]\n",
    "    for period in periods:\n",
    "        X_full.append(np.sin(2 * np.pi * t / period))\n",
    "        X_full.append(np.cos(2 * np.pi * t / period))\n",
    "    X_full = np.column_stack(X_full)\n",
    "    model_full = LinearRegression().fit(X_full, y)\n",
    "    r2_full = r2_score(y, model_full.predict(X_full))\n",
    "    \n",
    "    results['full'] = {\n",
    "        'r2': r2_full,\n",
    "        'delta_r2': r2_full - r2_base,\n",
    "        'prediction': model_full.predict(X_full)\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Fourier回帰実行\n",
    "fourier_results = {}\n",
    "\n",
    "for sensor in tqdm(representative_sensors, desc='Fourier回帰'):\n",
    "    data = resampled_results[sensor]['mean_linear']\n",
    "    fourier_results[sensor] = fourier_regression(data)\n",
    "\n",
    "# ΔR²サマリー\n",
    "fourier_scores = pd.DataFrame({\n",
    "    sensor: {\n",
    "        f'period_{p}': fourier_results[sensor].get(p, {}).get('delta_r2', np.nan)\n",
    "        for p in [7, 30, 365]\n",
    "    } | {'full_model': fourier_results[sensor]['full']['delta_r2']}\n",
    "    for sensor in representative_sensors\n",
    "}).T\n",
    "\n",
    "print('=== Fourier回帰 ΔR²スコア ===')\n",
    "display(fourier_scores.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# セル11b: Fourier回帰結果の可視化\n",
    "# ============================================================\n",
    "\n",
    "sensor = representative_sensors[0]\n",
    "data = resampled_results[sensor]['mean_linear'].dropna()\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "periods_to_plot = [7, 30, 365, 'full']\n",
    "titles = ['周期7日', '周期30日', '周期365日', '全周期モデル']\n",
    "\n",
    "for i, (period, title) in enumerate(zip(periods_to_plot, titles)):\n",
    "    ax = axes[i // 2, i % 2]\n",
    "    \n",
    "    # 実測値\n",
    "    ax.plot(data.index, data.values, 'b-', linewidth=0.5, alpha=0.5, label='実測値')\n",
    "    \n",
    "    # 予測値\n",
    "    pred = fourier_results[sensor][period]['prediction']\n",
    "    delta_r2 = fourier_results[sensor][period]['delta_r2']\n",
    "    ax.plot(data.index, pred, 'r-', linewidth=1, label=f'予測値 (ΔR²={delta_r2:.4f})')\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(f'{sensor} - Fourier回帰フィッティング', y=1.02, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / f'fourier_regression_{sensor}.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Prophet による分解（オプション）\n",
    "\n",
    "### 理論背景\n",
    "ProphetはMeta（旧Facebook）が開発した時系列予測ライブラリ。\n",
    "加法的/乗法的な季節性を自動検出し、休日効果やトレンド変化点も考慮できる。\n",
    "\n",
    "**注意**: Prophetは大規模データや長期間データに対して処理時間がかかる場合がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# セル12: Prophet分解（オプション）\n",
    "# ============================================================\n",
    "\n",
    "try:\n",
    "    from prophet import Prophet\n",
    "    PROPHET_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print('Prophet未インストール。pip install prophet でインストールしてください。')\n",
    "    PROPHET_AVAILABLE = False\n",
    "\n",
    "def prophet_decomposition(series):\n",
    "    \"\"\"\n",
    "    Prophetによる季節性分解\n",
    "    \"\"\"\n",
    "    if not PROPHET_AVAILABLE:\n",
    "        return None\n",
    "    \n",
    "    data = series.dropna().reset_index()\n",
    "    data.columns = ['ds', 'y']\n",
    "    \n",
    "    # モデル構築\n",
    "    model = Prophet(\n",
    "        yearly_seasonality=True,\n",
    "        weekly_seasonality=True,\n",
    "        daily_seasonality=False,\n",
    "        seasonality_mode='additive'\n",
    "    )\n",
    "    model.fit(data)\n",
    "    \n",
    "    # 予測（学習データに対して）\n",
    "    forecast = model.predict(data[['ds']])\n",
    "    \n",
    "    # MAPE計算\n",
    "    mape = np.mean(np.abs((data['y'] - forecast['yhat']) / data['y'])) * 100\n",
    "    \n",
    "    return {\n",
    "        'forecast': forecast,\n",
    "        'mape': mape,\n",
    "        'model': model\n",
    "    }\n",
    "\n",
    "# Prophet分解（時間がかかるため代表センサー1つのみ）\n",
    "prophet_results = {}\n",
    "\n",
    "if PROPHET_AVAILABLE:\n",
    "    sensor = representative_sensors[0]\n",
    "    print(f'Prophet分解実行中: {sensor}')\n",
    "    data = resampled_results[sensor]['mean_linear']\n",
    "    prophet_results[sensor] = prophet_decomposition(data)\n",
    "    \n",
    "    if prophet_results[sensor]:\n",
    "        print(f'MAPE: {prophet_results[sensor][\"mape\"]:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# セル12b: Prophet結果の可視化\n",
    "# ============================================================\n",
    "\n",
    "if PROPHET_AVAILABLE and prophet_results:\n",
    "    sensor = representative_sensors[0]\n",
    "    result = prophet_results[sensor]\n",
    "    model = result['model']\n",
    "    forecast = result['forecast']\n",
    "    \n",
    "    # 季節成分のプロット\n",
    "    fig = model.plot_components(forecast)\n",
    "    plt.suptitle(f'{sensor} - Prophet季節成分', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / f'prophet_components_{sensor}.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# セクション4：複数メトリクスの統合と2モード分析\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 スコア統合ロジックの設計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# セル13: スコア統合ロジック\n",
    "# ============================================================\n",
    "\n",
    "def normalize_score(value, min_val=0, max_val=1):\n",
    "    \"\"\"スコアを0-1に正規化\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return 0\n",
    "    return max(0, min(1, (value - min_val) / (max_val - min_val))) if max_val > min_val else 0\n",
    "\n",
    "def calculate_seasonality_scores(sensor, stl_res, acf_res, fourier_res, ls_res=None):\n",
    "    \"\"\"\n",
    "    複数手法のスコアを統合\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict: 各手法のスコアと統合スコア\n",
    "    \"\"\"\n",
    "    scores = {'sensor': sensor}\n",
    "    \n",
    "    # STLスコア（周期ごとの最大値を採用）\n",
    "    stl_scores = [stl_res.get(p, {}).get('score', 0) for p in [7, 30, 365]]\n",
    "    scores['stl_max'] = max(stl_scores) if stl_scores else 0\n",
    "    scores['stl_7'] = stl_res.get(7, {}).get('score', 0)\n",
    "    scores['stl_30'] = stl_res.get(30, {}).get('score', 0)\n",
    "    scores['stl_365'] = stl_res.get(365, {}).get('score', 0)\n",
    "    \n",
    "    # ACFスコア（有意なピークの絶対値）\n",
    "    if acf_res:\n",
    "        acf_peaks = acf_res['peaks']\n",
    "        scores['acf_7'] = abs(acf_peaks.get(7, {}).get('value', 0)) if acf_peaks.get(7, {}).get('significant', False) else 0\n",
    "        scores['acf_30'] = abs(acf_peaks.get(30, {}).get('value', 0)) if acf_peaks.get(30, {}).get('significant', False) else 0\n",
    "        scores['acf_365'] = abs(acf_peaks.get(365, {}).get('value', 0)) if acf_peaks.get(365, {}).get('significant', False) else 0\n",
    "        scores['acf_max'] = max(scores['acf_7'], scores['acf_30'], scores['acf_365'])\n",
    "    else:\n",
    "        scores['acf_7'] = scores['acf_30'] = scores['acf_365'] = scores['acf_max'] = 0\n",
    "    \n",
    "    # Fourier ΔR²スコア\n",
    "    scores['fourier_7'] = fourier_res.get(7, {}).get('delta_r2', 0)\n",
    "    scores['fourier_30'] = fourier_res.get(30, {}).get('delta_r2', 0)\n",
    "    scores['fourier_365'] = fourier_res.get(365, {}).get('delta_r2', 0)\n",
    "    scores['fourier_full'] = fourier_res.get('full', {}).get('delta_r2', 0)\n",
    "    \n",
    "    # Lomb-Scargleスコア（FAP < 0.05の場合のパワー値）\n",
    "    if ls_res:\n",
    "        ls_peaks = ls_res['peaks']\n",
    "        for p in [7, 30, 365]:\n",
    "            if ls_peaks.get(p, {}).get('significant', False):\n",
    "                scores[f'ls_{p}'] = normalize_score(ls_peaks[p]['power'], 0, 1)\n",
    "            else:\n",
    "                scores[f'ls_{p}'] = 0\n",
    "    else:\n",
    "        scores['ls_7'] = scores['ls_30'] = scores['ls_365'] = 0\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def classify_seasonality(scores, mode='strict'):\n",
    "    \"\"\"\n",
    "    季節性の確信度を判定\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    scores : dict\n",
    "        各手法のスコア\n",
    "    mode : str\n",
    "        'strict'（厳格モード）or 'exploratory'（探索モード）\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str: 'High', 'Medium', 'Low', 'None'\n",
    "    \"\"\"\n",
    "    if mode == 'strict':\n",
    "        # 厳格モード：複数手法で同時に検出\n",
    "        stl_ok = scores['stl_max'] > 0.5\n",
    "        acf_ok = scores['acf_max'] > 0.3\n",
    "        fourier_ok = scores['fourier_full'] > 0.1\n",
    "        \n",
    "        if stl_ok and acf_ok and fourier_ok:\n",
    "            return 'High'\n",
    "        elif (stl_ok and acf_ok) or (stl_ok and fourier_ok) or (acf_ok and fourier_ok):\n",
    "            return 'Medium'\n",
    "        elif stl_ok or acf_ok or fourier_ok:\n",
    "            return 'Low'\n",
    "        else:\n",
    "            return 'None'\n",
    "    \n",
    "    else:  # exploratory\n",
    "        # 探索モード：いずれか1つでも閾値超え\n",
    "        if scores['stl_max'] > 0.3 or scores['acf_max'] > 0.2 or scores['fourier_full'] > 0.05:\n",
    "            if scores['stl_max'] > 0.5 or scores['acf_max'] > 0.3 or scores['fourier_full'] > 0.1:\n",
    "                return 'High'\n",
    "            else:\n",
    "                return 'Medium'\n",
    "        elif scores['stl_max'] > 0.1 or scores['acf_max'] > 0.1 or scores['fourier_full'] > 0.02:\n",
    "            return 'Low'\n",
    "        else:\n",
    "            return 'None'\n",
    "\n",
    "# スコア計算\n",
    "all_scores = []\n",
    "\n",
    "for sensor in representative_sensors:\n",
    "    scores = calculate_seasonality_scores(\n",
    "        sensor,\n",
    "        stl_results.get(sensor, {}),\n",
    "        acf_results.get(sensor),\n",
    "        fourier_results.get(sensor, {}),\n",
    "        ls_results.get(sensor) if ls_results else None\n",
    "    )\n",
    "    scores['confidence_strict'] = classify_seasonality(scores, mode='strict')\n",
    "    scores['confidence_exploratory'] = classify_seasonality(scores, mode='exploratory')\n",
    "    all_scores.append(scores)\n",
    "\n",
    "scores_df = pd.DataFrame(all_scores).set_index('sensor')\n",
    "print('=== 季節性スコア統合結果 ===')\n",
    "display(scores_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 全センサー一括処理の試行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# セル14: 全センサー一括処理\n",
    "# ============================================================\n",
    "import traceback\n",
    "import psutil\n",
    "\n",
    "def process_sensor_batch(df, sensor_cols, resample_method='mean', interp_method='linear'):\n",
    "    \"\"\"\n",
    "    複数センサーを一括処理\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame: 各センサーの季節性スコア\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    errors = []\n",
    "    \n",
    "    for sensor in tqdm(sensor_cols, desc='一括処理'):\n",
    "        try:\n",
    "            # リサンプリング\n",
    "            data = resample_and_interpolate(df, sensor, resample_method, interp_method)\n",
    "            data = data.dropna()\n",
    "            \n",
    "            if len(data) < 100:\n",
    "                errors.append({'sensor': sensor, 'error': 'データ不足（< 100点）'})\n",
    "                continue\n",
    "            \n",
    "            # STL分解\n",
    "            stl_res = {}\n",
    "            for period in [7, 30, 365]:\n",
    "                result = perform_stl_decomposition(data, period)\n",
    "                if result:\n",
    "                    stl_res[period] = result\n",
    "            \n",
    "            # ACF\n",
    "            acf_res = calculate_acf_peaks(data)\n",
    "            \n",
    "            # Fourier\n",
    "            fourier_res = fourier_regression(data)\n",
    "            \n",
    "            # Lomb-Scargle\n",
    "            try:\n",
    "                ls_res = calculate_lomb_scargle(data)\n",
    "            except:\n",
    "                ls_res = None\n",
    "            \n",
    "            # スコア統合\n",
    "            scores = calculate_seasonality_scores(sensor, stl_res, acf_res, fourier_res, ls_res)\n",
    "            scores['confidence_strict'] = classify_seasonality(scores, mode='strict')\n",
    "            scores['confidence_exploratory'] = classify_seasonality(scores, mode='exploratory')\n",
    "            results.append(scores)\n",
    "            \n",
    "        except Exception as e:\n",
    "            errors.append({'sensor': sensor, 'error': str(e)})\n",
    "            traceback.print_exc()\n",
    "        \n",
    "        # メモリ解放\n",
    "        gc.collect()\n",
    "    \n",
    "    return pd.DataFrame(results).set_index('sensor'), pd.DataFrame(errors)\n",
    "\n",
    "# 処理実行（全センサー）\n",
    "start_time = time.time()\n",
    "initial_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB\n",
    "\n",
    "batch_scores, batch_errors = process_sensor_batch(df_raw, sensor_cols)\n",
    "\n",
    "end_time = time.time()\n",
    "final_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB\n",
    "\n",
    "print(f'\\n=== 処理完了 ===')\n",
    "print(f'処理時間: {end_time - start_time:.1f}秒')\n",
    "print(f'メモリ使用量: {initial_memory:.1f}MB → {final_memory:.1f}MB (差分: {final_memory - initial_memory:.1f}MB)')\n",
    "print(f'成功: {len(batch_scores)}センサー')\n",
    "print(f'エラー: {len(batch_errors)}センサー')\n",
    "\n",
    "if len(batch_errors) > 0:\n",
    "    print('\\nエラー詳細:')\n",
    "    display(batch_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 スコアランキング表の生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# セル15: スコアランキング\n",
    "# ============================================================\n",
    "\n",
    "def calculate_composite_score(row, weights=None):\n",
    "    \"\"\"\n",
    "    総合スコアを計算（加重平均）\n",
    "    \n",
    "    デフォルト重み:\n",
    "    - STL: 0.3\n",
    "    - ACF: 0.3\n",
    "    - Fourier: 0.4\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = {'stl': 0.3, 'acf': 0.3, 'fourier': 0.4}\n",
    "    \n",
    "    score = (\n",
    "        weights['stl'] * row['stl_max'] +\n",
    "        weights['acf'] * row['acf_max'] +\n",
    "        weights['fourier'] * min(row['fourier_full'] * 10, 1)  # 正規化\n",
    "    )\n",
    "    return score\n",
    "\n",
    "# 総合スコア計算\n",
    "if len(batch_scores) > 0:\n",
    "    batch_scores['composite_score'] = batch_scores.apply(calculate_composite_score, axis=1)\n",
    "    \n",
    "    # ランキング（総合スコア降順）\n",
    "    ranking = batch_scores.sort_values('composite_score', ascending=False)\n",
    "    \n",
    "    # 表示列を選択\n",
    "    display_cols = [\n",
    "        'composite_score', 'confidence_strict', 'confidence_exploratory',\n",
    "        'stl_max', 'acf_max', 'fourier_full',\n",
    "        'stl_7', 'stl_30', 'stl_365'\n",
    "    ]\n",
    "    \n",
    "    print('=== 季節性スコアランキング（上位） ===')\n",
    "    display(ranking[display_cols].head(10).round(4))\n",
    "    \n",
    "    # CSV出力\n",
    "    ranking.to_csv(OUTPUT_DIR / 'seasonality_scores_ranking.csv')\n",
    "    print(f'\\n保存: {OUTPUT_DIR / \"seasonality_scores_ranking.csv\"}')\n",
    "    \n",
    "    # 確信度別の集計\n",
    "    print('\\n=== 確信度別センサー数 ===')\n",
    "    print('厳格モード:')\n",
    "    print(ranking['confidence_strict'].value_counts())\n",
    "    print('\\n探索モード:')\n",
    "    print(ranking['confidence_exploratory'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# セクション5：可視化とレポート雛形\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 トップ10センサーの詳細レポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ??16: ???10???????????\n",
    "# ============================================================\n",
    "\n",
    "def create_detailed_report(df, sensor, stl_results, acf_results, ls_results, output_dir):\n",
    "    \"\"\"\n",
    "    ??????????????\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(18, 16))\n",
    "    \n",
    "    # ?????\n",
    "    data = resample_and_interpolate(df, sensor, 'mean', 'linear').dropna()\n",
    "    \n",
    "    # 1. STL???4????\n",
    "    # Original\n",
    "    ax1 = fig.add_subplot(4, 3, 1)\n",
    "    ax1.plot(data.index, data.values, 'b-', linewidth=0.5)\n",
    "    ax1.set_title('Original')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # STL?????30?????\n",
    "    stl_data = perform_stl_decomposition(data, 30)\n",
    "    if stl_data:\n",
    "        ax2 = fig.add_subplot(4, 3, 2)\n",
    "        ax2.plot(data.index, stl_data['trend'], 'g-', linewidth=1)\n",
    "        ax2.set_title('Trend')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        ax3 = fig.add_subplot(4, 3, 3)\n",
    "        ax3.plot(data.index, stl_data['seasonal'], 'r-', linewidth=0.5)\n",
    "        ax3.set_title(f\"Seasonal (score={stl_data['score']:.3f})\")\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        ax4 = fig.add_subplot(4, 3, 4)\n",
    "        ax4.plot(data.index, stl_data['residual'], 'gray', linewidth=0.5)\n",
    "        ax4.set_title('Residual')\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. ACF/PACF\n",
    "    max_lag = min(200, len(data) // 2 - 1)\n",
    "    if max_lag > 10:\n",
    "        ax5 = fig.add_subplot(4, 3, 5)\n",
    "        plot_acf(data, ax=ax5, lags=max_lag, alpha=0.05)\n",
    "        ax5.set_title('ACF')\n",
    "        for period in [7, 30]:\n",
    "            if period <= max_lag:\n",
    "                ax5.axvline(x=period, color='red', linestyle='--', alpha=0.5)\n",
    "        \n",
    "        ax6 = fig.add_subplot(4, 3, 6)\n",
    "        plot_pacf(data, ax=ax6, lags=min(50, max_lag), alpha=0.05, method='ywm')\n",
    "        ax6.set_title('PACF')\n",
    "    \n",
    "    # 3. Lomb-Scargle Periodogram\n",
    "    try:\n",
    "        ls_data = calculate_lomb_scargle(data)\n",
    "        ax7 = fig.add_subplot(4, 3, 7)\n",
    "        ax7.plot(ls_data['periods'], ls_data['power'], 'b-', linewidth=0.5)\n",
    "        ax7.set_xlim(0, 100)\n",
    "        ax7.set_title('Periodogram (0-100d)')\n",
    "        ax7.set_xlabel('Period (days)')\n",
    "        ax7.grid(True, alpha=0.3)\n",
    "        for period in [7, 30]:\n",
    "            ax7.axvline(x=period, color='red', linestyle='--', alpha=0.5)\n",
    "    except Exception:\n",
    "        ls_data = None\n",
    "        pass\n",
    "    \n",
    "    # 4. Fourier?????????\n",
    "    fourier_data = fourier_regression(data)\n",
    "    ax8 = fig.add_subplot(4, 3, 8)\n",
    "    ax8.plot(data.index, data.values, 'b-', linewidth=0.3, alpha=0.5, label='Actual')\n",
    "    ax8.plot(data.index, fourier_data['full']['prediction'], 'r-', linewidth=1, \n",
    "             label=f\"Fourier (?R?={fourier_data['full']['delta_r2']:.4f})\")\n",
    "    ax8.set_title('Fourier Regression')\n",
    "    ax8.legend()\n",
    "    ax8.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. ???????????\n",
    "    ax9 = fig.add_subplot(4, 3, 9)\n",
    "    ax9.axis('off')\n",
    "    stl_score_str = f\"{stl_data['score']:.4f}\" if stl_data else 'N/A'\n",
    "    if acf_results and sensor in acf_results and acf_results[sensor]:\n",
    "        peaks = acf_results[sensor]['peaks']\n",
    "        max_peak = max([abs(v['value']) for v in peaks.values() if v['value'] is not None], default=np.nan)\n",
    "        acf_str = f\"{max_peak:.4f}\" if np.isfinite(max_peak) else 'N/A'\n",
    "    else:\n",
    "        acf_str = 'N/A'\n",
    "    fourier_str = f\"{fourier_data['full']['delta_r2']:.4f}\" if fourier_data else 'N/A'\n",
    "\n",
    "    summary_text = f\"\"\"Seasonality Scores Summary\n\nSTL (period=30): {stl_score_str}\nACF |max peak|: {acf_str}\nFourier ?R? (full): {fourier_str}\n\nDetected periods: 7d, 30d\n\"\"\"\n",
    "    ax9.text(0.1, 0.5, summary_text, fontsize=10, family='monospace', verticalalignment='center')\n",
    "    \n",
    "    plt.suptitle(f\"{sensor} - Detailed Seasonality Report\", fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / f'detailed_report_{sensor}.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# ???10???????????\n",
    "if len(batch_scores) > 0:\n",
    "    top_sensors = ranking.head(10).index.tolist()\n",
    "    \n",
    "    for sensor in tqdm(top_sensors, desc='????????'):\n",
    "        create_detailed_report(\n",
    "            df_raw, sensor, \n",
    "            stl_results, acf_results, ls_results,\n",
    "            OUTPUT_DIR\n",
    "        )\n",
    "    \n",
    "    print(f\"\\n????????: {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 その他センサーの簡易サマリー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# セル17: 簡易サマリーグリッド\n",
    "# ============================================================\n",
    "\n",
    "def create_thumbnail_grid(df, sensor_cols, n_cols=4, figsize=(16, 20)):\n",
    "    \"\"\"\n",
    "    全センサーのサムネイルグリッドを作成\n",
    "    \"\"\"\n",
    "    n_sensors = len(sensor_cols)\n",
    "    n_rows = (n_sensors + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, sensor in enumerate(sensor_cols):\n",
    "        ax = axes[i]\n",
    "        data = resample_and_interpolate(df, sensor, 'mean', 'linear').dropna()\n",
    "        \n",
    "        # 時系列プロット\n",
    "        ax.plot(data.index, data.values, 'b-', linewidth=0.3)\n",
    "        \n",
    "        # スコア表示\n",
    "        if sensor in batch_scores.index:\n",
    "            score = batch_scores.loc[sensor, 'composite_score']\n",
    "            conf = batch_scores.loc[sensor, 'confidence_strict']\n",
    "            ax.set_title(f'{sensor}\\n({conf}, {score:.3f})', fontsize=8)\n",
    "        else:\n",
    "            ax.set_title(sensor, fontsize=8)\n",
    "        \n",
    "        ax.tick_params(axis='both', labelsize=6)\n",
    "        ax.grid(True, alpha=0.2)\n",
    "    \n",
    "    # 余ったサブプロットを非表示\n",
    "    for i in range(n_sensors, len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# サムネイルグリッド生成\n",
    "fig = create_thumbnail_grid(df_raw, sensor_cols)\n",
    "plt.savefig(OUTPUT_DIR / 'thumbnail_grid_all_sensors.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 インタラクティブ探索（Plotly）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# セル18: インタラクティブ可視化（Plotly）\n",
    "# ============================================================\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "def create_interactive_plot(df, sensor_cols):\n",
    "    \"\"\"\n",
    "    インタラクティブなセンサー探索ウィジェット\n",
    "    \"\"\"\n",
    "    # ドロップダウン\n",
    "    sensor_dropdown = widgets.Dropdown(\n",
    "        options=sensor_cols,\n",
    "        value=sensor_cols[0],\n",
    "        description='センサー:'\n",
    "    )\n",
    "    \n",
    "    # 周期スライダー\n",
    "    period_slider = widgets.IntSlider(\n",
    "        value=30,\n",
    "        min=7,\n",
    "        max=365,\n",
    "        step=1,\n",
    "        description='周期(日):'\n",
    "    )\n",
    "    \n",
    "    # 出力エリア\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    def update_plot(change):\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            sensor = sensor_dropdown.value\n",
    "            period = period_slider.value\n",
    "            \n",
    "            # データ準備\n",
    "            data = resample_and_interpolate(df, sensor, 'mean', 'linear').dropna()\n",
    "            \n",
    "            # STL分解\n",
    "            stl_result = perform_stl_decomposition(data, period)\n",
    "            \n",
    "            # Plotlyグラフ作成\n",
    "            fig = make_subplots(\n",
    "                rows=4, cols=1,\n",
    "                subplot_titles=('Original', 'Trend', f'Seasonal (period={period}d)', 'Residual'),\n",
    "                vertical_spacing=0.08\n",
    "            )\n",
    "            \n",
    "            # Original\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=data.index, y=data.values, mode='lines', name='Original',\n",
    "                          line=dict(width=0.5, color='blue')),\n",
    "                row=1, col=1\n",
    "            )\n",
    "            \n",
    "            if stl_result:\n",
    "                # Trend\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(x=data.index, y=stl_result['trend'], mode='lines', name='Trend',\n",
    "                              line=dict(width=1, color='green')),\n",
    "                    row=2, col=1\n",
    "                )\n",
    "                \n",
    "                # Seasonal\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(x=data.index, y=stl_result['seasonal'], mode='lines', name='Seasonal',\n",
    "                              line=dict(width=0.5, color='red')),\n",
    "                    row=3, col=1\n",
    "                )\n",
    "                \n",
    "                # Residual\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(x=data.index, y=stl_result['residual'], mode='lines', name='Residual',\n",
    "                              line=dict(width=0.5, color='gray')),\n",
    "                    row=4, col=1\n",
    "                )\n",
    "            \n",
    "            fig.update_layout(\n",
    "                height=800,\n",
    "                title_text=f'{sensor} - STL Decomposition (F_season={stl_result[\"score\"]:.4f if stl_result else \"N/A\"})',\n",
    "                showlegend=False\n",
    "            )\n",
    "            \n",
    "            fig.show()\n",
    "    \n",
    "    # イベントハンドラ\n",
    "    sensor_dropdown.observe(update_plot, names='value')\n",
    "    period_slider.observe(update_plot, names='value')\n",
    "    \n",
    "    # 初期プロット\n",
    "    update_plot(None)\n",
    "    \n",
    "    # ウィジェット表示\n",
    "    display(widgets.VBox([widgets.HBox([sensor_dropdown, period_slider]), output]))\n",
    "\n",
    "# インタラクティブプロット起動\n",
    "create_interactive_plot(df_raw, sensor_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# セクション6：探索結果のまとめと設計方針\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# セル19: 探索結果のまとめ\n",
    "# ============================================================\n",
    "\n",
    "print(\"\"\"╔══════════════════════════════════════════════════════════════════╗\n",
    "║                     探索結果のまとめ                              ║\n",
    "╚══════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "【1. 最もロバストな手法】\n",
    "━━━━━━━━━━━━━━━━━━━━━━\n",
    "推奨: STL分解 + Fourier回帰の組み合わせ\n",
    "\n",
    "理由:\n",
    "- STL分解: 外れ値にロバスト、視覚的に解釈しやすい\n",
    "- Fourier回帰: ΔR²で定量的な比較が可能\n",
    "- ACF: 補助的な確認に有効（有意性検定が明確）\n",
    "- Lomb-Scargle: 不等間隔データに最適だが、計算コスト高\n",
    "\n",
    "【2. 厳格/探索モードの閾値推奨値】\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "■ 厳格モード（High confidence）:\n",
    "  - STL F_season > 0.5\n",
    "  - ACF peak > 0.3（95%CI外）\n",
    "  - Fourier ΔR² > 0.1\n",
    "  → 3条件すべて満たす場合\n",
    "\n",
    "■ 探索モード（Medium/Low detection）:\n",
    "  - STL F_season > 0.3\n",
    "  - ACF peak > 0.2\n",
    "  - Fourier ΔR² > 0.05\n",
    "  → いずれか1つ満たす場合\n",
    "\n",
    "【3. 前処理パイプラインの最適順序】\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "1. 日次リサンプリング（median推奨、外れ値に強い）\n",
    "2. 欠測補間（linear、短期欠損向け）\n",
    "3. 外れ値検出（IQR法、シンプルで解釈しやすい）\n",
    "4. 変化点検出（PELT法、セグメント分割）\n",
    "5. セグメントごとに季節性分析\n",
    "\n",
    "【4. パイプライン化に向けた設計方針】\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "- 設定ファイル（YAML）で閾値・手法を外部化\n",
    "- センサー単位の並列処理（multiprocessing）\n",
    "- 中間結果のキャッシュ（pickle/parquet）\n",
    "- ログ出力とエラーハンドリングの標準化\n",
    "- CLI/API両対応のモジュール設計\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# セル20: 最終出力ファイル一覧\n",
    "# ============================================================\n",
    "\n",
    "print('=== 出力ファイル一覧 ===')\n",
    "for file in sorted(OUTPUT_DIR.glob('*')):\n",
    "    size_kb = file.stat().st_size / 1024\n",
    "    print(f'  {file.name}: {size_kb:.1f} KB')\n",
    "\n",
    "print(f'\\n出力ディレクトリ: {OUTPUT_DIR.absolute()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}